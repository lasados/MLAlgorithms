{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression. Theory\n",
    "\n",
    "\n",
    "1. Destignation\n",
    "\n",
    "    $a=\\left( {{a}_{1}}\\text{ }...\\text{  }{{a}_{n}} \\right)$- prediction\n",
    "\n",
    "    $y=\\left( {{y}_{1}}\\text{ }...\\text{  }{{y}_{n}} \\right)$ - target\n",
    "\n",
    "    $X=\\left( \\begin{align}\n",
    "      & 1\\text{  }{{x}_{11}}\\text{ }....\\text{  }{{x}_{1d}} \\\\ \n",
    "      & 1\\text{      }....... \\\\ \n",
    "      & 1\\text{      }....... \\\\ \n",
    "      & 1\\text{  }{{x}_{n1}}\\text{ }....\\text{   }{{x}_{nd}} \\\\ \n",
    "       \\end{align} \\right)$ - features\n",
    "\n",
    "    $w=\\left( \\begin{align}\n",
    "         & {{w}_{0}} \\\\ \n",
    "         & {{w}_{1}} \\\\ \n",
    "         & ... \\\\ \n",
    "         & {{w}_{d}} \\\\ \n",
    "        \\end{align} \\right)$ - weights\n",
    "\n",
    "    $a=Xw=np.dot(X,w)$ - prediction\n",
    "\n",
    "\n",
    "2. Probability conversion\n",
    "\n",
    "    ${{z}_{i}}=\\left\\langle w,{{x}_{i}} \\right\\rangle \\in R$ - dot product of the vector of weights and the vector of features of the j-th object.\n",
    "\n",
    "    $\\begin{align}\n",
    "      & {{e}^{\\left\\langle w,{{x}_{i}} \\right\\rangle }}\\in \\left( 0;+\\infty  \\right) \\\\ \n",
    "      & \\frac{{{e}^{\\left\\langle w,{{x}_{i}} \\right\\rangle }}}{1+{{e}^{\\left\\langle w,{{x}_{i}} \\right\\rangle }}}\\in \\left( 0;1 \\right) \\\\ \n",
    "    \\end{align}$ - probability space conversion\n",
    "\n",
    "    $\\pi (x)=\\frac{{{e}^{\\left\\langle w,{{x}_{i}} \\right\\rangle }}}{1+{{e}^{\\left\\langle w,{{x}_{i}} \\right\\rangle }}}$ - probability that ***y i-th*** is positive\n",
    "\n",
    "    $1-\\pi (x)=\\frac{1}{1+{{e}^{\\left\\langle w,{{x}_{i}} \\right\\rangle }}}$- probability that ***y i-th** is negative\n",
    " \n",
    " \n",
    "2. Likelihood function\n",
    "\n",
    "    $L(X,y,w)=\\prod\\limits_{i=1}^{n}{P(y|X,w)}$ - **likelihood function**\n",
    "\n",
    "    $\\begin{align}\n",
    "      & \\ln L(X,y,w)=\\ln \\left( \\prod\\limits_{i=1}^{n}{P(y|X,w)} \\right)=\\sum\\limits_{i=1}^{n}{\\ln P(y|X,w)}=\\sum\\limits_{k=1}^{K}{\\ln P({{y}_{k}}=+1|X,w)}+\\sum\\limits_{l=1}^{L}{\\ln P({{y}_{k}}=0|X,w)}= \\\\ \n",
    "      & =\\sum\\limits_{i=1}^{n}{\\left( {{y}_{i}}\\ln \\pi ({{x}_{i}})+\\left( 1-{{y}_{i}} \\right)\\ln \\left( 1-\\pi ({{x}_{i}}) \\right) \\right)} \\\\ \n",
    "    \\end{align}$\n",
    "\n",
    "    $Q(X,y,w)=-\\ln L(X,y,w)=-\\sum\\limits_{i=1}^{n}{\\left( {{y}_{i}}\\ln \\pi ({{x}_{i}})+\\left( 1-{{y}_{i}} \\right)\\ln \\left( 1-\\pi ({{x}_{i}}) \\right) \\right)}$ - **Log-Reg cost function**\n",
    "\n",
    "\n",
    "3. Gradient of LogLoss\n",
    "\n",
    "    $a=\\pi (x)=\\frac{{{e}^{\\left\\langle w,x \\right\\rangle }}}{1+{{e}^{\\left\\langle w,x \\right\\rangle }}}=\\frac{1}{1+{{e}^{-\\left\\langle w,x \\right\\rangle }}}=\\frac{1}{1+{{e}^{-z}}}=\\sigma (z)$ - sigmoid function\n",
    "\n",
    "    $Q(a,y)=-\\sum\\limits_{i=1}^{n}{\\left( {{y}_{i}}\\ln {{a}_{i}}+\\left( 1-{{y}_{i}} \\right)\\ln \\left( 1-{{a}_{i}} \\right) \\right)}$- cost function\n",
    "\n",
    "    $L(a,y)=-\\left( y\\ln a+(1-y)\\ln (1-a) \\right)$-loss function\n",
    "\n",
    "    $\\frac{\\partial L}{\\partial z}=\\frac{\\partial L}{\\partial a}\\frac{\\partial a}{\\partial z}=\\left( -\\frac{y}{a}+\\frac{1-y}{1-a} \\right)a(1-a)=a-y=({{a}_{1}}-{{y}_{1}},...,{{a}_{n}}-{{y}_{n}})$ - derivation of loss function\n",
    "\n",
    "\n",
    "4. Gradient descent\n",
    "    $w:=w-\\alpha \\frac{\\partial Q}{\\partial w}$ - gradient descent\n",
    "\n",
    "    $\\frac{\\partial L}{\\partial w}=\\frac{\\partial L}{\\partial z}\\frac{\\partial z}{\\partial w}=\\frac{\\partial L}{\\partial z}x$ \n",
    "\n",
    "    $\\frac{\\partial Q}{\\partial w}=\\sum{\\frac{\\partial L}{\\partial w}}=(a-y)X=np.dot(a-y,X)$\n",
    "\n",
    "    $w:=w-\\alpha \\cdot (a-y)X$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Import libs and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "cancer_dataset = load_breast_cancer()\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Create matrix of features and target vector. Append constant feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__constant</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   __constant  mean radius  mean texture  mean perimeter  mean area  \\\n",
       "0           1        17.99         10.38          122.80     1001.0   \n",
       "1           1        20.57         17.77          132.90     1326.0   \n",
       "2           1        19.69         21.25          130.00     1203.0   \n",
       "3           1        11.42         20.38           77.58      386.1   \n",
       "4           1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   mean symmetry  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = pd.DataFrame(cancer_dataset.data, columns=cancer_dataset.feature_names)\n",
    "cancer.insert(0, '__constant', 1)\n",
    "\n",
    "X = cancer.values\n",
    "y = cancer_dataset.target\n",
    "\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Train/dev/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dev_test_split(X, y, shuffle=True, train_size=0.7, dev_size=0.2):\n",
    "    \"\"\"\n",
    "    Splits given arrays of X and y on three parts.\n",
    "    Arguments:\n",
    "        X - np.array of features, X.shape = (N, nx)\n",
    "        y - np.array of target, y.shape = (N, 1)\n",
    "        N - number of samples\n",
    "    Returns:\n",
    "        [X_train, y_train], [X_dev, y_dev], [X_test, y_test]\n",
    "    \"\"\"\n",
    "    \n",
    "    N, nx = X.shape\n",
    "    \n",
    "    \n",
    "    assert y.shape[0] == N, \"X and y arrays have different number of samples\"\n",
    "    assert train_size + dev_size <= 1.0, \"Bad size of sets\"\n",
    "    \n",
    "    idx = np.array(range(N))\n",
    "    if shuffle:\n",
    "        random.shuffle(idx)\n",
    "    \n",
    "    idx_train = idx[0: int(train_size*N)]\n",
    "    idx_dev = idx[int(train_size*N): int((train_size + dev_size)*N)]\n",
    "    idx_test = idx[int((train_size + dev_size)*N):]\n",
    "    \n",
    "    \n",
    "    X_train, y_train = X[idx_train], y[idx_train]\n",
    "    X_dev, y_dev = X[idx_dev], y[idx_dev]  \n",
    "    X_test, y_test = X[idx_test], y[idx_test]\n",
    "    \n",
    "    return [X_train, y_train], [X_dev, y_dev], [X_test, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Standartization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standart_scaler(X_train, X_dev, X_test):\n",
    "    \"\"\"\n",
    "    Scales arrays based on train set with Standart_Scale.\n",
    "    Arguments:\n",
    "        X_train, X_dev, X_test - np.arrays\n",
    "    Returns:\n",
    "        X_train_scale, X_dev_scale, X_test_scale - np.arrays\n",
    "    \"\"\"\n",
    "    \n",
    "    mu = np.mean(X_train, axis=0)\n",
    "    sigma = np.std(X_train, axis=0)\n",
    "    sigma = np.where(sigma==0, 1, sigma)    # replace std=0 on 1\n",
    "    \n",
    "    X_train_scale = (X_train - mu) / sigma\n",
    "    X_dev_scale = (X_dev - mu) / sigma\n",
    "    X_test_scale = (X_test - mu) / sigma\n",
    "    \n",
    "    return X_train_scale, X_dev_scale, X_test_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(nx):\n",
    "    \"\"\"\n",
    "    Initialize weight with random numbers.\n",
    "    Arguments:\n",
    "        nx - int, X.shape = (N, nx) \n",
    "    Returns:\n",
    "        w - np.array\n",
    "    \"\"\"\n",
    "    \n",
    "    w = np.random.random(nx)\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_loss(X_train, y_train, w, lamda=1.0):\n",
    "    \n",
    "    N = X_train.shape[0]\n",
    "    Z = np.dot(X_train, w)\n",
    "    A = 1/(1 + np.exp(-Z))\n",
    "    Q = -np.sum(y_train*np.log(A) + (1 - y_train)*np.log(1 - A)) + lamda/2*np.sum(w**2)\n",
    "    \n",
    "    dw = np.dot((A - y_train), X_train) + lamda*w\n",
    "    \n",
    "    return Q, dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(w, dw, learning_rate=0.01):\n",
    "    return w - learning_rate*dw\n",
    "\n",
    "def predict(X, w):\n",
    "    Z = np.dot(X, w)\n",
    "    A = 1/(1 + np.exp(-Z))\n",
    "    \n",
    "    return A\n",
    "\n",
    "def logreg_model(X, y, n_iter=10000):\n",
    "    \n",
    "    # Split data\n",
    "    [X_train, y_train], [X_dev, y_dev], [X_test, y_test] = train_dev_test_split(X, y)\n",
    "    \n",
    "    # Scale data\n",
    "    X_train_scale, X_dev_scale, X_test_scale = standart_scaler(X_train, X_dev, X_test)\n",
    "    \n",
    "    # Number of features\n",
    "    nx = X_train_scale.shape[1]\n",
    "    \n",
    "    # Init weights\n",
    "    w = init_weights(nx)\n",
    "    \n",
    "    # Init list with loss\n",
    "    Q_iter = []\n",
    "    \n",
    "    # Learning\n",
    "    for _ in range(n_iter):\n",
    "        Q, dw = logreg_loss(X_train_scale, y_train, w)\n",
    "        \n",
    "        Q_iter.append(Q)\n",
    "        \n",
    "        w = update_weights(w, dw)\n",
    "    \n",
    "    # Prediction\n",
    "    y_dev_pred = predict(X_dev_scale, w)\n",
    "        \n",
    "    return Q_iter, w, y_dev_pred, y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(q_iter):\n",
    "    \n",
    "    iterations = list(range(len(q_iter)))\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.title('Loss function')\n",
    "    \n",
    "    plt.plot(iterations, q_iter, 'r--', label='loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Learning and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anatoly\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "C:\\Users\\Anatoly\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in multiply\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q_iter, w, y_dev_pred, y_dev = logreg_model(X, y)\n",
    "plot_loss(Q_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
